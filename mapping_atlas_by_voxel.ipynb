{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping the Allen Mouse 3D Atlas to individual sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the deformation fields and affine parameters to transform the annotations from the reference space to a specimen's image volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache, MouseConnectivityApi\n",
    "from allensdk.api.queries.image_download_api import ImageDownloadApi\n",
    "import SimpleITK as sitk\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import nrrd\n",
    "import scipy.ndimage as ndi\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, this process will be applied to a section from a sample specimen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 100141219 # Image series ID for an experiment\n",
    "section_no = 62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlas and Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mouse connectivity cache is used to acquire the necessary atlas and image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MouseConnectivityCache(resolution=25,manifest_file='./mouse_connectivity_manifest.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno,meta = mcc.get_annotation_volume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsp = mcc.get_reference_space()\n",
    "rsp.remove_unassigned(); # This removes ids that are not in this particular reference space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = rsp.structure_tree.get_name_map() # dictionary mapping ids to structure names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acrnm_map = rsp.structure_tree.get_id_acronym_map() # dictionary mapping acronyms to ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = rsp.structure_tree.get_colormap() # the colormap used for the allen 3D mouse atlas ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get structure ids for regions of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structure_ids(acrnms):\n",
    "    regions = []\n",
    "    for acrnm in acrnms:\n",
    "        regions.append(acrnm_map[acrnm])\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_of_interest = get_structure_ids(['GENd','GENv','LP','POL','APN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1008, 1014, 218, 1029, 215]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_of_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and set transform parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The registration of an image stack to the reference space involves a global (affine) registration followed by a local deformation. To map the atlas back onto the image space, we must first reverse the deformation and then the affine transformation. Thus, we acquire the deformation field and affine transform parameters and build the reverse transforms with SimpleITK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get deformation field and set transform\n",
    "dfmfld = mcc.get_deformation_field(ID,header_path='./{}/dfmfld.mhd'.format(ID),voxel_path='./{}/dfmfld.raw'.format(ID))\n",
    "temp = sitk.ReadImage('./{}/dfmfld.mhd'.format(ID),sitk.sitkVectorFloat64)\n",
    "dfmfld_transform = sitk.DisplacementFieldTransform(temp)\n",
    "\n",
    "# Get affine parameters and set transform\n",
    "temp = mcc.get_affine_parameters(ID,direction='trv',file_name='./{}/aff_param.txt'.format(ID))\n",
    "aff_trans = sitk.AffineTransform(3)\n",
    "aff_trans.SetParameters(temp.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get image section and associated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the mouse connectivity api and image download api to download the image section of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-04 09:49:53,867 allensdk.api.api.retrieve_file_over_http INFO     Downloading URL: http://api.brain-map.org/api/v2/image_download/102127598?downsample=4&range=0,911,0,975,0,4095\n"
     ]
    }
   ],
   "source": [
    "mca = MouseConnectivityApi()\n",
    "ida = ImageDownloadApi()\n",
    "\n",
    "# Get equalization values\n",
    "details = mca.get_experiment_detail(ID)\n",
    "equal = pd.DataFrame(details).T.loc['equalization'].values[0]\n",
    "r = [equal['red_lower'],equal['red_upper'],equal['green_lower'],equal['green_upper'],equal['blue_lower'],equal['blue_upper']]\n",
    "# Get 2D resolution\n",
    "twoD = 1.0/details[0]['sub_images'][0]['resolution']\n",
    "size = 25*twoD/(2**4)\n",
    "\n",
    "# Get section id\n",
    "sections_frame = pd.DataFrame(ida.section_image_query(ID))\n",
    "section_id = sections_frame[sections_frame.section_number==section_no].id.values[0]\n",
    "\n",
    "# Download image\n",
    "ida.download_image(section_id,downsample=4,range=r,file_path='./{0}/{0}.jpg'.format(ID))\n",
    "\n",
    "# Load image\n",
    "img = Image.open('./{0}/{0}.jpg'.format(ID))\n",
    "arr = np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify atlas sections in image section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to identify the sections in the atlas that map to the image section of interest. To do this, a mask of the entire brain is generated from which we get all the points within the brain reference space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_mask = rsp.make_structure_mask([997])\n",
    "root_points = np.array(np.where(root_mask)).T.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all structures in section\n",
    "# Transform root points\n",
    "dfp = np.array(list(map(dfmfld_transform.TransformPoint,root_points*25)))\n",
    "tfp = np.array(list(map(aff_trans.TransformPoint,dfp)))\n",
    "# Find atlas slices corresponding to this section\n",
    "sections = np.round(tfp[:,2]/100)\n",
    "loc = np.where(sections == section_no)\n",
    "# Find annotated ids in these slices\n",
    "anno_loc = np.unique(root_points[loc][:,0])\n",
    "structures_in_section = np.unique(anno[anno_loc.astype(int),:,:])[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the structures in the image section are found, the specific regions that may not appear in the annotated volumes, such as parent structures, can be added to the list of structures in the section. These are then sorted so that parent structures don't overlap children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    if region not in structures_in_section:\n",
    "        structures_in_section = np.hstack((structures_in_section,region))\n",
    "# Sort structure ids by ontology\n",
    "sorted_indx = np.argsort(np.array(list(map(lambda x:len(x),rsp.structure_tree.ancestor_ids(structures_in_section)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map structures to image section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can begin mapping the structures to this image section. We create an area_image to map the structure areas to, and a boundary image to map the desired region boundaries to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_image = arr.copy()\n",
    "boundary_image = arr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num,struct in enumerate(structures_in_section[sorted_indx]):\n",
    "    if struct != 997: # There is no need to map the root structure here, since this was calculated previously\n",
    "        # For each structure, the points (voxels) within the volume are acquired.\n",
    "        mask = rsp.make_structure_mask([struct])\n",
    "        points = np.array(np.where(mask)).T.astype(float)\n",
    "        \n",
    "        # These points are transformed using the deformation and affine transforms.\n",
    "        dfp = np.array(list(map(dfmfld_transform.TransformPoint,points*25)))\n",
    "        tfp = np.array(list(map(aff_trans.TransformPoint,dfp)))\n",
    "        \n",
    "        # Since these points will map to several sections, only the points in our desired section are selected\n",
    "        sections = np.round(tfp[:,2]/100)\n",
    "        loc = np.where(sections == section_no)\n",
    "    \n",
    "    # Map points to 2D section\n",
    "    mapped_points = tfp[loc,:2]*twoD/(2**4)\n",
    "    mapped_points = mapped_points.squeeze()\n",
    "    next_points = mapped_points + size\n",
    "    rounded_mapped_points,rounded_next_points = np.round(mapped_points).reshape((-1,2)),np.round(next_points).reshape((-1,2))\n",
    "    \n",
    "    # Place points on blank array and fill in gaps.\n",
    "    blank = np.zeros((arr.shape[0],arr.shape[1]))\n",
    "    for i,rounded_mapped_point in enumerate(rounded_mapped_points):\n",
    "        rounded_next_point = rounded_next_points[i]\n",
    "        rounded_mapped_point = rounded_mapped_point.astype(int)\n",
    "        rounded_next_point = rounded_next_point.astype(int)\n",
    "        blank[rounded_mapped_point[1]:rounded_next_point[1],rounded_mapped_point[0]:rounded_next_point[0]] = 1\n",
    "    area = ndi.binary_closing(ndi.binary_fill_holes(blank).astype(int)).astype(int)\n",
    "    \n",
    "    # Place structre in area image\n",
    "    color = colormap[struct]\n",
    "    area_mask = np.where(area==1)\n",
    "    for i in np.arange(3):\n",
    "        area_image[:,:,i][area_mask] = color[i]\n",
    "    \n",
    "    # Draw region boundaries in boundary image\n",
    "    if struct in regions:\n",
    "        inner = area.copy()\n",
    "        for i in np.arange(6):\n",
    "            inner = ndi.binary_erosion(inner)\n",
    "        boundary = area - inner.astype(int)\n",
    "        boundary_mask = np.where(boundary == 1)\n",
    "        for i in np.arange(3):\n",
    "            boundary_image[:,:,i][boundary_mask] = 0\n",
    "        boundary_image[:,:,2][boundary_mask] = 255\n",
    "\n",
    "# Save area and boundary images        \n",
    "area_img = Image.fromarray(area_image.astype(np.uint8))\n",
    "area_img.save('./{}/area.png'.format(ID))\n",
    "boundary_img = Image.fromarray(boundary_image.astype(np.uint8))\n",
    "boundary_img.save('./{}/boundary.png'.format(ID))\n",
    "\n",
    "# Create and save area composite\n",
    "cbg = Image.open('./{0}/{0}.jpg'.format(ID))\n",
    "fg = Image.open('./{}/area.png'.format(ID))\n",
    "cbg_alpha = Image.new(\"L\",cbg.size,255)\n",
    "fg_alpha = Image.new(\"L\",cbg.size,80)\n",
    "cbg.putalpha(cbg_alpha)\n",
    "fg.putalpha(fg_alpha)\n",
    "comp = Image.alpha_composite(cbg,fg)\n",
    "comp.save('./{}/color_composite.png'.format(ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
